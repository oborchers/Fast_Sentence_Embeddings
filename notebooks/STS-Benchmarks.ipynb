{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STS Benchmark Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors, FastTextKeyedVectors\n",
    "\n",
    "from fse.models import Average, SIF, uSIF\n",
    "from fse import CSplitIndexedList\n",
    "\n",
    "from re import sub\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(threadName)s : %(levelname)s : %(message)s',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we require the sentences from the STS benchmark dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tSim: 2.5\tA girl is styling her hair.             \tA girl is brushing her hair.            \t\n",
      "1\tSim: 3.6\tA group of men play soccer on the beach.\tA group of boys are playing soccer on the beach.\t\n",
      "2\tSim: 5.0\tOne woman is measuring another woman's ankle.\tA woman measures another woman's ankle. \t\n",
      "3\tSim: 4.2\tA man is cutting up a cucumber.         \tA man is slicing a cucumber.            \t\n",
      "4\tSim: 1.5\tA man is playing a harp.                \tA man is playing a keyboard.            \t\n"
     ]
    }
   ],
   "source": [
    "file= \"../fse/eval/sts-test.csv\"\n",
    "similarities, sent_a, sent_b = [], [], []\n",
    "with open(file, \"r\") as f:\n",
    "    for l in f:\n",
    "        line = l.rstrip().split(\"\\t\")\n",
    "        similarities.append(float(line[4]))\n",
    "        sent_a.append(line[5])\n",
    "        sent_b.append(line[6])\n",
    "similarities = np.array(similarities)\n",
    "assert len(similarities) == len(sent_a) == len(sent_b)\n",
    "task_length = len(similarities)\n",
    "\n",
    "for i, obj in enumerate(zip(similarities, sent_a, sent_b)):\n",
    "    print(f\"{i}\\tSim: {obj[0].round(3):.1f}\\t{obj[1]:40s}\\t{obj[2]:40s}\\t\")\n",
    "    if i == 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these sentence requires some preparation (i.e. tokenization) to be used in the core input formats.\n",
    "To reproduce the results from the uSIF paper this part is taken from https://github.com/kawine/usif/blob/master/usif.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_punc = re.compile('.*[A-Za-z0-9].*')\n",
    "\n",
    "def prep_token(token):\n",
    "    t = token.lower().strip(\"';.:()\").strip('\"')\n",
    "    t = 'not' if t == \"n't\" else t\n",
    "    return re.split(r'[-]', t)\n",
    "\n",
    "def prep_sentence(sentence):\n",
    "    tokens = []\n",
    "    for token in word_tokenize(sentence):\n",
    "        if not_punc.match(token):\n",
    "            tokens = tokens + prep_token(token)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the IndexedList object. The IndexedList extends the previously constructed sent_a and sent_b list together. We additionally provide a custom function \"prep_sentence\" which performs all the prepocessing for a single sentence. Therefore we need the extention **CSplitIndexedList**, which provides you the option to provide a custom split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = CSplitIndexedList(sent_a, sent_b, custom_split=prep_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IndexedList returns the core object required for fse to train a sentence embedding: A tuple. This object constists of words (a list of strings) and its corresponding index. The latter is important if multiple cores access the input queue simultaneously. Thus it must be always provided. The index represents the row in the matrix where it can later be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['a', 'girl', 'is', 'styling', 'her', 'hair'], 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that IndexedList does not convert the sentences inplace but only on calling the __getitem__ method in order to turn the sentence into a tuple. You can access the original sentence using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A girl is styling her hair.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.items[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the models\n",
    "\n",
    "It is required for us to load the models as BaseKeyedVectors or as an BaseWordEmbeddingsModel. For this notebook, I already converted the models to a BaseKeyedVectors instance and saved the corresponding instance on my external harddrive. You have to replicate these steps yourself, because getting all the files can be a bit difficult, as the total filesize is around 15 GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_models = \"/Volumes/Ext_HDD/Models/Static/\"\n",
    "models, results = {}, {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code performs a disk-to-ram training. Passing a path to __wv_mapfile_path__ will store the corresponding word vectors (wv) as a numpy memmap array. This is required, because loading all vectors into ram would would take up a lot of storage unecessary. The wv.vectors file will be replace by its memmap representation, which is why the next models do not require the wv_mapfile_path argument, as they access the same memmap object.\n",
    "\n",
    "The lang_freq=\"en\" induces the frequencies of the words according to the wordfreq package. This functionality allows you to work with pre-trained embeddings which don't come with frequency information. The method overwrites the counts in the glove.wv.vocab class, so that all further models also benefit from this induction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 10:38:54,395 : MainThread : INFO : loading Word2VecKeyedVectors object from /Volumes/Ext_HDD/Models/Static/glove.840B.300d.model\n",
      "2019-09-11 10:38:59,173 : MainThread : INFO : loading vectors from /Volumes/Ext_HDD/Models/Static/glove.840B.300d.model.vectors.npy with mmap=None\n",
      "2019-09-11 10:39:05,118 : MainThread : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-09-11 10:39:05,130 : MainThread : INFO : loaded /Volumes/Ext_HDD/Models/Static/glove.840B.300d.model\n",
      "2019-09-11 10:39:05,138 : MainThread : INFO : loading pre-existing wv from /Users/oliverborchers/Library/Mobile Documents/com~apple~CloudDocs/Diss/Medium/Fast_Sentence_Embeddings/notebooks/data/glove_wv.vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before memmap 2635050112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 10:39:05,544 : MainThread : INFO : no frequency mode: using wordfreq for estimation of frequency for language: en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After memmap 136\n"
     ]
    }
   ],
   "source": [
    "glove = KeyedVectors.load(path_to_models+\"glove.840B.300d.model\")\n",
    "\n",
    "print(f\"Before memmap {sys.getsizeof(glove.vectors)}\")\n",
    "\n",
    "models[f\"CBOW-Glove\"] = Average(glove, wv_mapfile_path=\"data/glove\", lang_freq=\"en\")\n",
    "\n",
    "print(f\"After memmap {sys.getsizeof(glove.vectors)}\")\n",
    "\n",
    "models[f\"SIF-Glove\"] = SIF(glove, components=15)\n",
    "models[f\"uSIF-Glove\"] = uSIF(glove,length=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do all the vectors contain the same content?\n",
    "(models[f\"SIF-Glove\"].wv.vectors == models[f\"uSIF-Glove\"].wv.vectors).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to load the KeyedVectors using the kwarg mmap=\"r\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 10:39:16,246 : MainThread : INFO : loading Word2VecKeyedVectors object from /Volumes/Ext_HDD/Models/Static/google_news.model\n",
      "2019-09-11 10:39:22,918 : MainThread : INFO : loading vectors from /Volumes/Ext_HDD/Models/Static/google_news.model.vectors.npy with mmap=r\n",
      "2019-09-11 10:39:22,929 : MainThread : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-09-11 10:39:22,929 : MainThread : INFO : loaded /Volumes/Ext_HDD/Models/Static/google_news.model\n",
      "2019-09-11 10:39:22,932 : MainThread : INFO : no frequency mode: using wordfreq for estimation of frequency for language: en\n"
     ]
    }
   ],
   "source": [
    "w2v = KeyedVectors.load(path_to_models+\"google_news.model\", mmap=\"r\")\n",
    "\n",
    "models[f\"CBOW-W2V\"] = Average(w2v, lang_freq=\"en\")\n",
    "models[f\"SIF-W2V\"] = SIF(w2v, components=10)\n",
    "models[f\"uSIF-W2V\"] = uSIF(w2v, length=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 10:39:25,448 : MainThread : INFO : loading FastTextKeyedVectors object from /Volumes/Ext_HDD/Models/Static/ft_crawl_300d_2m.model\n",
      "2019-09-11 10:39:32,132 : MainThread : INFO : loading vectors from /Volumes/Ext_HDD/Models/Static/ft_crawl_300d_2m.model.vectors.npy with mmap=r\n",
      "2019-09-11 10:39:32,142 : MainThread : INFO : loading vectors_vocab from /Volumes/Ext_HDD/Models/Static/ft_crawl_300d_2m.model.vectors_vocab.npy with mmap=r\n",
      "2019-09-11 10:39:32,154 : MainThread : INFO : loading vectors_ngrams from /Volumes/Ext_HDD/Models/Static/ft_crawl_300d_2m.model.vectors_ngrams.npy with mmap=r\n",
      "2019-09-11 10:39:32,161 : MainThread : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-09-11 10:39:32,162 : MainThread : INFO : setting ignored attribute vectors_vocab_norm to None\n",
      "2019-09-11 10:39:32,163 : MainThread : INFO : setting ignored attribute vectors_ngrams_norm to None\n",
      "2019-09-11 10:39:32,164 : MainThread : INFO : setting ignored attribute buckets_word to None\n",
      "2019-09-11 10:39:32,165 : MainThread : INFO : loaded /Volumes/Ext_HDD/Models/Static/ft_crawl_300d_2m.model\n",
      "2019-09-11 10:39:32,168 : MainThread : INFO : no frequency mode: using wordfreq for estimation of frequency for language: en\n"
     ]
    }
   ],
   "source": [
    "ft = FastTextKeyedVectors.load(path_to_models+\"ft_crawl_300d_2m.model\", mmap=\"r\")\n",
    "models[f\"CBOW-FT\"] = Average(ft, lang_freq=\"en\")\n",
    "models[f\"SIF-FT\"] = SIF(ft, components=10)\n",
    "models[f\"uSIF-FT\"] = uSIF(ft, length=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 10:39:34,534 : MainThread : INFO : loading Word2VecKeyedVectors object from /Volumes/Ext_HDD/Models/Static/paranmt.model\n",
      "2019-09-11 10:39:34,800 : MainThread : INFO : loading vectors from /Volumes/Ext_HDD/Models/Static/paranmt.model.vectors.npy with mmap=r\n",
      "2019-09-11 10:39:34,811 : MainThread : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-09-11 10:39:34,812 : MainThread : INFO : loaded /Volumes/Ext_HDD/Models/Static/paranmt.model\n",
      "2019-09-11 10:39:34,814 : MainThread : INFO : no frequency mode: using wordfreq for estimation of frequency for language: en\n"
     ]
    }
   ],
   "source": [
    "paranmt = KeyedVectors.load(path_to_models+\"paranmt.model\", mmap=\"r\")\n",
    "\n",
    "models[f\"CBOW-Paranmt\"] = Average(paranmt, lang_freq=\"en\")\n",
    "models[f\"SIF-Paranmt\"] = SIF(paranmt, components=10)\n",
    "models[f\"uSIF-Paranmt\"] = uSIF(paranmt, length=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 10:39:34,941 : MainThread : INFO : loading Word2VecKeyedVectors object from /Volumes/Ext_HDD/Models/Static/paragram_sl999_czeng.model\n",
      "2019-09-11 10:39:35,099 : MainThread : INFO : loading vectors from /Volumes/Ext_HDD/Models/Static/paragram_sl999_czeng.model.vectors.npy with mmap=r\n",
      "2019-09-11 10:39:35,108 : MainThread : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-09-11 10:39:35,109 : MainThread : INFO : loaded /Volumes/Ext_HDD/Models/Static/paragram_sl999_czeng.model\n",
      "2019-09-11 10:39:35,111 : MainThread : INFO : no frequency mode: using wordfreq for estimation of frequency for language: en\n"
     ]
    }
   ],
   "source": [
    "paragram = KeyedVectors.load(path_to_models+\"paragram_sl999_czeng.model\", mmap=\"r\")\n",
    "\n",
    "models[f\"CBOW-Paragram\"] = Average(paragram, lang_freq=\"en\")\n",
    "models[f\"SIF-Paragram\"] = SIF(paragram, components=10)\n",
    "models[f\"uSIF-Paragram\"] = uSIF(paragram, length=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation of the results for the STS benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are finally able to compute the STS benchmark values for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to compute the similarities between two sentences.\n",
    "# Task length is the length of the sts dataset.\n",
    "def compute_similarities(task_length, model):\n",
    "    sims = []\n",
    "    for i, j in zip(range(task_length), range(task_length, 2*task_length)):\n",
    "        sims.append(model.sv.similarity(i,j))\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 10:39:35,222 : MainThread : INFO : scanning all indexed sentences and their word counts\n",
      "2019-09-11 10:39:35,727 : MainThread : INFO : finished scanning 2758 sentences with an average length of 9 and 27528 total words\n",
      "2019-09-11 10:39:36,788 : MainThread : INFO : estimated memory for 2758 sentences with 300 dimensions and 2195875 vocabulary: 2524 MB (2 GB)\n",
      "2019-09-11 10:39:36,789 : MainThread : INFO : initializing sentence vectors for 2758 sentences\n",
      "2019-09-11 10:39:36,846 : MainThread : INFO : begin training\n",
      "2019-09-11 10:39:37,353 : MainThread : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 10:39:37,354 : MainThread : INFO : training on 2758 effective sentences with 27351 effective words took 0s with 5430 sentences/s\n",
      "2019-09-11 10:39:37,385 : MainThread : INFO : scanning all indexed sentences and their word counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW-Glove 40.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 10:39:37,798 : MainThread : INFO : finished scanning 2758 sentences with an average length of 9 and 27528 total words\n",
      "2019-09-11 10:39:38,648 : MainThread : INFO : estimated memory for 2758 sentences with 300 dimensions and 2195875 vocabulary: 2524 MB (2 GB)\n",
      "2019-09-11 10:39:38,649 : MainThread : INFO : initializing sentence vectors for 2758 sentences\n",
      "2019-09-11 10:39:38,662 : MainThread : INFO : pre-computing SIF weights for 2195875 words\n",
      "2019-09-11 10:39:40,394 : MainThread : INFO : begin training\n",
      "2019-09-11 10:39:40,830 : MainThread : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 10:39:40,887 : MainThread : INFO : computing 15 principal components took 0s\n",
      "2019-09-11 10:39:40,889 : MainThread : INFO : removing 15 principal components took 0s\n",
      "2019-09-11 10:39:40,890 : MainThread : INFO : training on 2758 effective sentences with 27351 effective words took 0s with 6316 sentences/s\n",
      "2019-09-11 10:39:40,926 : MainThread : INFO : scanning all indexed sentences and their word counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIF-Glove 71.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 10:39:41,411 : MainThread : INFO : finished scanning 2758 sentences with an average length of 9 and 27528 total words\n",
      "2019-09-11 10:39:42,249 : MainThread : INFO : estimated memory for 2758 sentences with 300 dimensions and 2195875 vocabulary: 2524 MB (2 GB)\n",
      "2019-09-11 10:39:42,249 : MainThread : INFO : initializing sentence vectors for 2758 sentences\n",
      "2019-09-11 10:39:42,264 : MainThread : INFO : pre-computing uSIF weights for 2195875 words\n",
      "2019-09-11 10:39:50,589 : MainThread : INFO : begin training\n",
      "2019-09-11 10:39:51,119 : MainThread : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 10:39:51,138 : MainThread : INFO : computing 5 principal components took 0s\n",
      "2019-09-11 10:39:51,141 : MainThread : INFO : removing 5 principal components took 0s\n",
      "2019-09-11 10:39:51,142 : MainThread : INFO : training on 2758 effective sentences with 27351 effective words took 0s with 5197 sentences/s\n",
      "2019-09-11 10:39:51,186 : MainThread : INFO : scanning all indexed sentences and their word counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uSIF-Glove 67.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 10:39:51,643 : MainThread : INFO : finished scanning 2758 sentences with an average length of 9 and 27528 total words\n",
      "2019-09-11 10:39:53,870 : MainThread : INFO : estimated memory for 2758 sentences with 300 dimensions and 3000000 vocabulary: 3447 MB (3 GB)\n",
      "2019-09-11 10:39:53,871 : MainThread : INFO : initializing sentence vectors for 2758 sentences\n",
      "2019-09-11 10:39:53,952 : MainThread : INFO : begin training\n",
      "2019-09-11 10:39:54,566 : MainThread : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 10:39:54,567 : MainThread : INFO : training on 2758 effective sentences with 23116 effective words took 0s with 4482 sentences/s\n",
      "2019-09-11 10:39:54,606 : MainThread : INFO : scanning all indexed sentences and their word counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW-W2V 61.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 10:39:55,064 : MainThread : INFO : finished scanning 2758 sentences with an average length of 9 and 27528 total words\n",
      "2019-09-11 10:39:56,280 : MainThread : INFO : estimated memory for 2758 sentences with 300 dimensions and 3000000 vocabulary: 3447 MB (3 GB)\n",
      "2019-09-11 10:39:56,280 : MainThread : INFO : initializing sentence vectors for 2758 sentences\n",
      "2019-09-11 10:39:56,294 : MainThread : INFO : pre-computing SIF weights for 3000000 words\n",
      "2019-09-11 10:39:59,084 : MainThread : INFO : begin training\n",
      "2019-09-11 10:39:59,549 : MainThread : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 10:39:59,570 : MainThread : INFO : computing 10 principal components took 0s\n",
      "2019-09-11 10:39:59,573 : MainThread : INFO : removing 10 principal components took 0s\n",
      "2019-09-11 10:39:59,574 : MainThread : INFO : training on 2758 effective sentences with 23116 effective words took 0s with 5922 sentences/s\n",
      "2019-09-11 10:39:59,617 : MainThread : INFO : scanning all indexed sentences and their word counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIF-W2V 71.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 10:40:00,087 : MainThread : INFO : finished scanning 2758 sentences with an average length of 9 and 27528 total words\n",
      "2019-09-11 10:40:01,227 : MainThread : INFO : estimated memory for 2758 sentences with 300 dimensions and 3000000 vocabulary: 3447 MB (3 GB)\n",
      "2019-09-11 10:40:01,228 : MainThread : INFO : initializing sentence vectors for 2758 sentences\n",
      "2019-09-11 10:40:01,246 : MainThread : INFO : pre-computing uSIF weights for 3000000 words\n",
      "2019-09-11 10:40:12,911 : MainThread : INFO : begin training\n",
      "2019-09-11 10:40:13,382 : MainThread : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 10:40:13,403 : MainThread : INFO : computing 5 principal components took 0s\n",
      "2019-09-11 10:40:13,407 : MainThread : INFO : removing 5 principal components took 0s\n",
      "2019-09-11 10:40:13,408 : MainThread : INFO : training on 2758 effective sentences with 23116 effective words took 0s with 5839 sentences/s\n",
      "2019-09-11 10:40:13,445 : MainThread : INFO : scanning all indexed sentences and their word counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uSIF-W2V 66.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 10:40:13,890 : MainThread : INFO : finished scanning 2758 sentences with an average length of 9 and 27528 total words\n",
      "2019-09-11 10:40:15,745 : MainThread : INFO : estimated memory for 2758 sentences with 300 dimensions and 2000000 vocabulary: 6877 MB (6 GB)\n",
      "2019-09-11 10:40:15,746 : MainThread : WARNING : The embeddings will likely not fit into RAM. Consider to use mapfile_path\n",
      "2019-09-11 10:40:15,747 : MainThread : INFO : initializing sentence vectors for 2758 sentences\n",
      "2019-09-11 10:40:15,804 : MainThread : INFO : begin training\n",
      "2019-09-11 10:40:16,861 : MainThread : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 10:40:16,862 : MainThread : INFO : training on 2758 effective sentences with 27528 effective words took 1s with 2605 sentences/s\n",
      "2019-09-11 10:40:16,894 : MainThread : INFO : scanning all indexed sentences and their word counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW-FT 48.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 10:40:17,317 : MainThread : INFO : finished scanning 2758 sentences with an average length of 9 and 27528 total words\n",
      "2019-09-11 10:40:18,202 : MainThread : INFO : estimated memory for 2758 sentences with 300 dimensions and 2000000 vocabulary: 6877 MB (6 GB)\n",
      "2019-09-11 10:40:18,203 : MainThread : WARNING : The embeddings will likely not fit into RAM. Consider to use mapfile_path\n",
      "2019-09-11 10:40:18,204 : MainThread : INFO : initializing sentence vectors for 2758 sentences\n",
      "2019-09-11 10:40:18,221 : MainThread : INFO : pre-computing SIF weights for 2000000 words\n",
      "2019-09-11 10:40:20,197 : MainThread : INFO : begin training\n",
      "2019-09-11 10:40:20,713 : MainThread : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 10:40:20,735 : MainThread : INFO : computing 10 principal components took 0s\n",
      "2019-09-11 10:40:20,737 : MainThread : INFO : removing 10 principal components took 0s\n",
      "2019-09-11 10:40:20,738 : MainThread : INFO : training on 2758 effective sentences with 27528 effective words took 0s with 5331 sentences/s\n",
      "2019-09-11 10:40:20,779 : MainThread : INFO : scanning all indexed sentences and their word counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIF-FT 73.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 10:40:21,219 : MainThread : INFO : finished scanning 2758 sentences with an average length of 9 and 27528 total words\n",
      "2019-09-11 10:40:22,061 : MainThread : INFO : estimated memory for 2758 sentences with 300 dimensions and 2000000 vocabulary: 6877 MB (6 GB)\n",
      "2019-09-11 10:40:22,062 : MainThread : WARNING : The embeddings will likely not fit into RAM. Consider to use mapfile_path\n",
      "2019-09-11 10:40:22,063 : MainThread : INFO : initializing sentence vectors for 2758 sentences\n",
      "2019-09-11 10:40:22,078 : MainThread : INFO : pre-computing uSIF weights for 2000000 words\n",
      "2019-09-11 10:40:30,034 : MainThread : INFO : begin training\n",
      "2019-09-11 10:40:30,553 : MainThread : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 10:40:30,578 : MainThread : INFO : computing 5 principal components took 0s\n",
      "2019-09-11 10:40:30,581 : MainThread : INFO : removing 5 principal components took 0s\n",
      "2019-09-11 10:40:30,582 : MainThread : INFO : training on 2758 effective sentences with 27528 effective words took 0s with 5309 sentences/s\n",
      "2019-09-11 10:40:30,624 : MainThread : INFO : scanning all indexed sentences and their word counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uSIF-FT 69.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 10:40:31,120 : MainThread : INFO : finished scanning 2758 sentences with an average length of 9 and 27528 total words\n",
      "2019-09-11 10:40:31,190 : MainThread : INFO : estimated memory for 2758 sentences with 300 dimensions and 77224 vocabulary: 91 MB (0 GB)\n",
      "2019-09-11 10:40:31,191 : MainThread : INFO : initializing sentence vectors for 2758 sentences\n",
      "2019-09-11 10:40:31,206 : MainThread : INFO : begin training\n",
      "2019-09-11 10:40:31,889 : MainThread : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 10:40:31,890 : MainThread : INFO : training on 2758 effective sentences with 27441 effective words took 0s with 4030 sentences/s\n",
      "2019-09-11 10:40:31,921 : MainThread : INFO : scanning all indexed sentences and their word counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW-Paranmt 79.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 10:40:32,297 : MainThread : INFO : finished scanning 2758 sentences with an average length of 9 and 27528 total words\n",
      "2019-09-11 10:40:32,327 : MainThread : INFO : estimated memory for 2758 sentences with 300 dimensions and 77224 vocabulary: 91 MB (0 GB)\n",
      "2019-09-11 10:40:32,328 : MainThread : INFO : initializing sentence vectors for 2758 sentences\n",
      "2019-09-11 10:40:32,340 : MainThread : INFO : pre-computing SIF weights for 77224 words\n",
      "2019-09-11 10:40:32,396 : MainThread : INFO : begin training\n",
      "2019-09-11 10:40:32,772 : MainThread : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 10:40:32,792 : MainThread : INFO : computing 10 principal components took 0s\n",
      "2019-09-11 10:40:32,794 : MainThread : INFO : removing 10 principal components took 0s\n",
      "2019-09-11 10:40:32,795 : MainThread : INFO : training on 2758 effective sentences with 27441 effective words took 0s with 7319 sentences/s\n",
      "2019-09-11 10:40:32,832 : MainThread : INFO : scanning all indexed sentences and their word counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIF-Paranmt 76.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 10:40:33,253 : MainThread : INFO : finished scanning 2758 sentences with an average length of 9 and 27528 total words\n",
      "2019-09-11 10:40:33,282 : MainThread : INFO : estimated memory for 2758 sentences with 300 dimensions and 77224 vocabulary: 91 MB (0 GB)\n",
      "2019-09-11 10:40:33,283 : MainThread : INFO : initializing sentence vectors for 2758 sentences\n",
      "2019-09-11 10:40:33,296 : MainThread : INFO : pre-computing uSIF weights for 77224 words\n",
      "2019-09-11 10:40:33,533 : MainThread : INFO : begin training\n",
      "2019-09-11 10:40:33,964 : MainThread : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 10:40:33,992 : MainThread : INFO : computing 5 principal components took 0s\n",
      "2019-09-11 10:40:33,994 : MainThread : INFO : removing 5 principal components took 0s\n",
      "2019-09-11 10:40:33,995 : MainThread : INFO : training on 2758 effective sentences with 27441 effective words took 0s with 6374 sentences/s\n",
      "2019-09-11 10:40:34,043 : MainThread : INFO : scanning all indexed sentences and their word counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uSIF-Paranmt 79.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 10:40:34,572 : MainThread : INFO : finished scanning 2758 sentences with an average length of 9 and 27528 total words\n",
      "2019-09-11 10:40:34,650 : MainThread : INFO : estimated memory for 2758 sentences with 300 dimensions and 77224 vocabulary: 91 MB (0 GB)\n",
      "2019-09-11 10:40:34,651 : MainThread : INFO : initializing sentence vectors for 2758 sentences\n",
      "2019-09-11 10:40:34,662 : MainThread : INFO : begin training\n",
      "2019-09-11 10:40:35,184 : MainThread : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 10:40:35,185 : MainThread : INFO : training on 2758 effective sentences with 27441 effective words took 0s with 5270 sentences/s\n",
      "2019-09-11 10:40:35,214 : MainThread : INFO : scanning all indexed sentences and their word counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW-Paragram 50.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 10:40:35,613 : MainThread : INFO : finished scanning 2758 sentences with an average length of 9 and 27528 total words\n",
      "2019-09-11 10:40:35,648 : MainThread : INFO : estimated memory for 2758 sentences with 300 dimensions and 77224 vocabulary: 91 MB (0 GB)\n",
      "2019-09-11 10:40:35,649 : MainThread : INFO : initializing sentence vectors for 2758 sentences\n",
      "2019-09-11 10:40:35,665 : MainThread : INFO : pre-computing SIF weights for 77224 words\n",
      "2019-09-11 10:40:35,724 : MainThread : INFO : begin training\n",
      "2019-09-11 10:40:36,294 : MainThread : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 10:40:36,319 : MainThread : INFO : computing 10 principal components took 0s\n",
      "2019-09-11 10:40:36,322 : MainThread : INFO : removing 10 principal components took 0s\n",
      "2019-09-11 10:40:36,323 : MainThread : INFO : training on 2758 effective sentences with 27441 effective words took 0s with 4828 sentences/s\n",
      "2019-09-11 10:40:36,364 : MainThread : INFO : scanning all indexed sentences and their word counts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIF-Paragram 73.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-09-11 10:40:36,831 : MainThread : INFO : finished scanning 2758 sentences with an average length of 9 and 27528 total words\n",
      "2019-09-11 10:40:36,859 : MainThread : INFO : estimated memory for 2758 sentences with 300 dimensions and 77224 vocabulary: 91 MB (0 GB)\n",
      "2019-09-11 10:40:36,860 : MainThread : INFO : initializing sentence vectors for 2758 sentences\n",
      "2019-09-11 10:40:36,871 : MainThread : INFO : pre-computing uSIF weights for 77224 words\n",
      "2019-09-11 10:40:37,130 : MainThread : INFO : begin training\n",
      "2019-09-11 10:40:37,598 : MainThread : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-09-11 10:40:37,626 : MainThread : INFO : computing 5 principal components took 0s\n",
      "2019-09-11 10:40:37,628 : MainThread : INFO : removing 5 principal components took 0s\n",
      "2019-09-11 10:40:37,629 : MainThread : INFO : training on 2758 effective sentences with 27441 effective words took 0s with 5878 sentences/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uSIF-Paragram 73.64\n"
     ]
    }
   ],
   "source": [
    "for k, m in models.items():\n",
    "    m_type  = k.split(\"-\")[0]\n",
    "    emb_type = k.split(\"-\")[1]\n",
    "    m.train(sentences)\n",
    "    r = pearsonr(similarities, compute_similarities(task_length, m))[0].round(4) * 100\n",
    "    results[f\"{m_type}-{emb_type}\"] = r\n",
    "    print(k, f\"{r:2.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CBOW-Glove</th>\n",
       "      <td>40.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIF-Glove</th>\n",
       "      <td>71.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uSIF-Glove</th>\n",
       "      <td>67.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBOW-W2V</th>\n",
       "      <td>61.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIF-W2V</th>\n",
       "      <td>71.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uSIF-W2V</th>\n",
       "      <td>66.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBOW-FT</th>\n",
       "      <td>48.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIF-FT</th>\n",
       "      <td>73.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uSIF-FT</th>\n",
       "      <td>69.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBOW-Paranmt</th>\n",
       "      <td>79.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIF-Paranmt</th>\n",
       "      <td>76.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uSIF-Paranmt</th>\n",
       "      <td>79.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBOW-Paragram</th>\n",
       "      <td>50.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIF-Paragram</th>\n",
       "      <td>73.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uSIF-Paragram</th>\n",
       "      <td>73.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Pearson\n",
       "CBOW-Glove       40.41\n",
       "SIF-Glove        71.95\n",
       "uSIF-Glove       67.16\n",
       "CBOW-W2V         61.54\n",
       "SIF-W2V          71.12\n",
       "uSIF-W2V         66.99\n",
       "CBOW-FT          48.49\n",
       "SIF-FT           73.38\n",
       "uSIF-FT          69.40\n",
       "CBOW-Paranmt     79.85\n",
       "SIF-Paranmt      76.75\n",
       "uSIF-Paranmt     79.02\n",
       "CBOW-Paragram    50.38\n",
       "SIF-Paragram     73.86\n",
       "uSIF-Paragram    73.64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Pearson\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you closely study the values above you will find that:\n",
    "- SIF-Glove is almost equivalent to the values reported in http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark\n",
    "- CBOW-Paranmt is a little better than ParaNMT Word Avg. in https://www.aclweb.org/anthology/W18-3012\n",
    "- uSIF-Paranmt is a little worse than ParaNMT+UP in https://www.aclweb.org/anthology/W18-3012\n",
    "- uSIF-Paragram is a little worse than PSL+UP in https://www.aclweb.org/anthology/W18-3012\n",
    "\n",
    "However, I guess those differences might arise due to differences in preprocessing. Too bad we didn't hit 80. If you have any ideas why those values don't match exactly, feel free to contact me anytime."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
