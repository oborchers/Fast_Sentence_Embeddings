{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fse - Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to fse - fast sentence embeddings. The library is intended to compute sentence embeddings as fast as possible. \n",
    "It offers a simple and easy to understand syntax for you to use in your own projects. Before we start with any model, lets have a look at the input types.\n",
    "All fse models require an iterable/generator which produces a tuple. The tuple has two fields: words and index. The index is required for the multi-thread processing, as sentences might not be processed sequentially. The index dictates, which row of the corresponding sentence vector matrix the sentence belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(threadName)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'world']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "s = ([\"Hello\", \"world\"], 0)\n",
    "print(s[0])\n",
    "print(s[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words of the tuple will always consist of a list of strings. Otherwise the train method will raise an Error. However, most input data is available as a list of strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to deal with this common input format, fse provides the IndexedList and some variants, which handel all required data operations for you. You can provide multiple lists (or sets) which will all be merged into a single list. This eases work if you have to work with the STS datasets.\n",
    "\n",
    "The multiple types of indexed lists. Let's go through them one by one:\n",
    "- IndexedList: for already pre-splitted sentences\n",
    "- **C**IndexedList: for already pre-splitted sentences with a custom index for each sentence\n",
    "- SplitIndexedList: for sentences which have not been splitted. Will split the strings\n",
    "- Split**C**IndexedList: for sentences which have not been splitted and with a custom index for each sentence\n",
    "- **C**SplitIndexedList: for sentences which have not been splitted. Will split the strings. You can provide a custom split function\n",
    "- **C**Split*C*IndexedList: for sentences where you want to provide a custom index and a custom split function.\n",
    "\n",
    "*Note*: These are ordered by speed. Meaning, that IndexedList is the fastest, while **C**Split*C*IndexedList is the slowest variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Hello', 'there'], 0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fse import SplitIndexedList\n",
    "\n",
    "sentences_a = [\"Hello there\", \"how are you?\"]\n",
    "sentences_b = [\"today is a good day\", \"Lorem ipsum\"]\n",
    "\n",
    "s = SplitIndexedList(sentences_a, sentences_b)\n",
    "print(len(s))\n",
    "s[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save memory, we do not convert the original lists inplace. The conversion will only take place once you call the getitem method. To access the original data, call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello there', 'how are you?', 'today is a good day', 'Lorem ipsum']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data is already preprocessed as a list of lists you can just use the IndexedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Hello', 'there'], 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fse import IndexedList\n",
    "\n",
    "sentences_splitted = [\"Hello there\".split(), \"how are you?\".split()]\n",
    "s = IndexedList(sentences_splitted)\n",
    "print(len(s))\n",
    "s[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you want to provide your own splitting function, you can pass a callable to the **C**SplitIndexedList class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['hello', 'there'], 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fse import CSplitIndexedList\n",
    "\n",
    "def split_func(string):\n",
    "    return string.lower().split()\n",
    "\n",
    "s = CSplitIndexedList(sentences_a, custom_split=split_func)\n",
    "print(len(s))\n",
    "s[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to stream a file from disk (where each line corresponds to a sentence) you can use the IndexedLineDocument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fse import IndexedLineDocument\n",
    "doc = IndexedLineDocument(\"../test/test_data/test_sentences.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t['Good', 'stuff', 'i', 'just', 'wish', 'it', 'lasted', 'longer']\n",
      "1\t['Hp', 'makes', 'qualilty', 'stuff']\n",
      "2\t['I', 'like', 'it']\n",
      "3\t['Try', 'it', 'you', 'will', 'like', 'it']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for s in doc:\n",
    "    print(f\"{s[1]}\\t{s[0]}\")\n",
    "    i += 1\n",
    "    if i == 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are later working with the similarity of sentences, the IndexedLineDocument provides you the option to access each line by its corresponding index. This helps you in determining the similarity of sentences, as the most_similar method would otherwise just return indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I feel like i just got screwed'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model / Performing inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a fse model is simple. You only need a pre-trained word embedding model which you use during the initializiation of the fse model you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:00:42,265 : MainThread : INFO : Lock 23311648346896 acquired on /home/oborchers/.cache/huggingface/hub/fse--glove-wiki-gigaword-100.main.3282d5e7c5e979c2411ba9703d63a46243a2047e/glove-wiki-gigaword-100.model.lock\n",
      "2022-04-10 21:00:42,267 : MainThread : INFO : Lock 23311648346896 released on /home/oborchers/.cache/huggingface/hub/fse--glove-wiki-gigaword-100.main.3282d5e7c5e979c2411ba9703d63a46243a2047e/glove-wiki-gigaword-100.model.lock\n",
      "2022-04-10 21:00:47,947 : MainThread : INFO : Lock 23311648386016 acquired on /home/oborchers/.cache/huggingface/hub/fse--glove-wiki-gigaword-100.main.3282d5e7c5e979c2411ba9703d63a46243a2047e/glove-wiki-gigaword-100.model.vectors.npy.lock\n",
      "2022-04-10 21:00:47,949 : MainThread : INFO : Lock 23311648386016 released on /home/oborchers/.cache/huggingface/hub/fse--glove-wiki-gigaword-100.main.3282d5e7c5e979c2411ba9703d63a46243a2047e/glove-wiki-gigaword-100.model.vectors.npy.lock\n",
      "2022-04-10 21:00:47,951 : MainThread : INFO : loading Vectors object from /home/oborchers/.cache/huggingface/hub/fse--glove-wiki-gigaword-100.main.3282d5e7c5e979c2411ba9703d63a46243a2047e/glove-wiki-gigaword-100.model\n",
      "2022-04-10 21:00:48,915 : MainThread : INFO : loading vectors from /home/oborchers/.cache/huggingface/hub/fse--glove-wiki-gigaword-100.main.3282d5e7c5e979c2411ba9703d63a46243a2047e/glove-wiki-gigaword-100.model.vectors.npy with mmap=None\n",
      "2022-04-10 21:00:48,970 : MainThread : INFO : setting ignored attribute vectors_norm to None\n",
      "2022-04-10 21:00:51,758 : MainThread : INFO : KeyedVectors lifecycle event {'fname': '/home/oborchers/.cache/huggingface/hub/fse--glove-wiki-gigaword-100.main.3282d5e7c5e979c2411ba9703d63a46243a2047e/glove-wiki-gigaword-100.model', 'datetime': '2022-04-10T21:00:51.731098', 'gensim': '4.0.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-4.15.0-173-generic-x86_64-with-glibc2.10', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "from fse import Vectors\n",
    "import gensim.downloader as api\n",
    "data = api.load(\"quora-duplicate-questions\")\n",
    "glove = Vectors.from_pretrained(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6468640\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "for d in data:\n",
    "    # Let's blow up the data a bit by replicating each sentence.\n",
    "    for i in range(8):\n",
    "        sentences.append(d[\"question1\"].split())\n",
    "        sentences.append(d[\"question2\"].split())\n",
    "s = IndexedList(sentences)\n",
    "print(len(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have about 6468640 sentences we want to compute the embeddings for. If you import the FAST_VERSION variable as follows you can ensure, that the compiliation of the cython routines worked correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "from fse.models.average import FAST_VERSION, MAX_WORDS_IN_BATCH\n",
    "print(MAX_WORDS_IN_BATCH)\n",
    "print(FAST_VERSION)\n",
    "# 1 -> The fast version works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:01:20,427 : MainThread : INFO : no frequency mode: using wordfreq for estimation of frequency for language: en\n"
     ]
    }
   ],
   "source": [
    "from fse.models import uSIF\n",
    "model = uSIF(glove, workers=1, lang_freq=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:01:21,811 : MainThread : INFO : scanning all indexed sentences and their word counts\n",
      "2022-04-10 21:01:26,812 : MainThread : INFO : SCANNING : finished 4268552 sentences with 47204452 words\n",
      "2022-04-10 21:01:29,815 : MainThread : WARNING : found 16 empty sentences\n",
      "2022-04-10 21:01:29,816 : MainThread : INFO : finished scanning 6468640 sentences with an average length of 11 and 71556728 total words\n",
      "2022-04-10 21:01:30,127 : MainThread : INFO : estimated memory for 6468640 sentences with 100 dimensions and 400000 vocabulary: 2621 MB (2 GB)\n",
      "2022-04-10 21:01:30,129 : MainThread : INFO : initializing sentence vectors for 6468640 sentences\n",
      "2022-04-10 21:01:58,270 : MainThread : INFO : pre-computing uSIF weights for 400000 words\n",
      "2022-04-10 21:01:59,606 : MainThread : INFO : begin training\n",
      "2022-04-10 21:02:04,625 : MainThread : INFO : PROGRESS : finished 20.57% with 1330528 sentences and 10112720 words, 266105 sentences/s\n",
      "2022-04-10 21:02:09,626 : MainThread : INFO : PROGRESS : finished 40.11% with 2594574 sentences and 19736065 words, 252809 sentences/s\n",
      "2022-04-10 21:02:14,629 : MainThread : INFO : PROGRESS : finished 59.45% with 3845556 sentences and 29254320 words, 250196 sentences/s\n",
      "2022-04-10 21:02:19,631 : MainThread : INFO : PROGRESS : finished 78.39% with 5070852 sentences and 38592790 words, 245059 sentences/s\n",
      "2022-04-10 21:02:24,632 : MainThread : INFO : PROGRESS : finished 96.63% with 6250702 sentences and 47579860 words, 235970 sentences/s\n",
      "2022-04-10 21:02:25,623 : MainThread : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-04-10 21:02:25,624 : MainThread : INFO : sampling 2684354 vectors to compute principal components\n",
      "2022-04-10 21:02:37,478 : MainThread : INFO : computing 5 principal components took 11s\n",
      "2022-04-10 21:02:44,538 : MainThread : INFO : removing 5 principal components took 7s\n",
      "2022-04-10 21:02:44,539 : MainThread : INFO : training on 6468624 effective sentences with 49255184 effective words took 26s with 248624 sentences/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6468624, 49255184)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models training speed revolves at around 300,000 - 500,000 sentences / seconds. That means we finish the task in about 10 seconds. This is **heavily dependent** on the input processing. If you train ram-to-ram it is naturally faster than any ram-to-disk or disk-to-disk varianty. Similarly, the speed depends on the workers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the sif model is trained, you can perform additional inferences for unknown sentences. This two step process for new data is required, as computing the principal components for models like SIF and uSIF will require a fair amount of sentences. If you want the vector for a single sentence (which is out of the training vocab), just use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:02:44,544 : MainThread : INFO : scanning all indexed sentences and their word counts\n",
      "2022-04-10 21:02:44,545 : MainThread : INFO : finished scanning 1 sentences with an average length of 3 and 3 total words\n",
      "2022-04-10 21:02:44,546 : MainThread : INFO : removing 5 principal components took 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.58816600e-01, -2.95302048e-02,  2.75351852e-02,\n",
       "        -2.84114152e-01, -7.67392814e-02,  4.69468027e-01,\n",
       "        -1.08480439e-01,  2.74309274e-02, -6.55729175e-02,\n",
       "        -3.49144369e-01, -3.67706642e-03, -7.37217665e-02,\n",
       "         1.99556813e-01,  1.58444345e-01, -1.19665325e-01,\n",
       "        -2.94139415e-01,  9.47405249e-02, -1.60569757e-01,\n",
       "        -3.78268361e-01,  3.62190604e-01, -1.04472280e-01,\n",
       "         2.73262203e-01, -3.63826789e-02, -1.77271560e-01,\n",
       "         1.13316491e-01,  9.37681645e-02, -2.24020645e-01,\n",
       "        -5.91988862e-02,  4.76207793e-01,  1.19424753e-01,\n",
       "         2.50848651e-01,  3.00246894e-01,  3.93525660e-01,\n",
       "         1.26845583e-01,  9.48224217e-04,  2.53242493e-01,\n",
       "         1.82835817e-01,  6.30666614e-02,  2.79401392e-01,\n",
       "        -1.32174164e-01, -1.33375764e-01,  1.35822147e-01,\n",
       "         2.27280006e-01, -1.15767486e-01, -1.42402038e-01,\n",
       "        -1.17349595e-01, -4.09546375e-01,  3.27205539e-01,\n",
       "         4.02800381e-01, -1.04363769e-01, -1.11321002e-01,\n",
       "        -2.22490475e-01,  8.87305886e-02,  1.40741229e-01,\n",
       "         9.31955799e-02, -4.58287299e-01,  5.18307090e-04,\n",
       "         2.35566050e-02, -1.00434214e-01,  1.92349762e-01,\n",
       "         5.87247610e-02,  6.50634110e-01,  3.70587595e-02,\n",
       "        -1.77234858e-01,  5.73643446e-02, -8.31981450e-02,\n",
       "         2.63155580e-01,  2.63526857e-01,  2.41669610e-01,\n",
       "        -1.44437030e-02, -1.83978081e-01,  1.32746503e-01,\n",
       "         4.74075712e-02, -5.11893451e-01, -2.29704395e-01,\n",
       "         4.10661429e-01,  3.22975338e-01, -2.24843532e-01,\n",
       "        -4.89681363e-02,  8.36608559e-02, -5.19971400e-02,\n",
       "         4.39288676e-01,  3.65279317e-01, -2.31688872e-01,\n",
       "        -5.32944202e-01, -1.05634883e-01, -3.59344721e-01,\n",
       "         1.47738606e-01, -2.77038217e-01, -2.75986940e-01,\n",
       "        -8.08256269e-02,  7.00389221e-02,  5.83384752e-01,\n",
       "        -2.55951770e-02, -4.16631788e-01, -1.48772165e-01,\n",
       "        -2.40149587e-01,  1.64508954e-01, -7.53749311e-02,\n",
       "         2.90106297e-01]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = (\"Hello my friends\".split(), 0)\n",
    "model.infer([tmp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to query the model or perform similarity computations we can just access the model.sv (sentence vectors) object and use its method. To get a vector for an index, just call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06577122,  0.00125362,  0.02861076,  0.29774222,  0.16603038,\n",
       "       -0.3326527 , -0.25274056, -0.11763255, -0.00691745, -0.09893274,\n",
       "       -0.03162983,  0.11619435, -0.06521351, -0.2655796 , -0.19060446,\n",
       "       -0.0539908 , -0.00769202,  0.06885006,  0.02343568,  0.1532896 ,\n",
       "        0.09342796,  0.04696935, -0.23081023,  0.1498743 , -0.14505012,\n",
       "        0.02421208,  0.05296347,  0.06859872, -0.07599732,  0.00725658,\n",
       "       -0.24535023,  0.22700995, -0.09825065, -0.09442319,  0.13708887,\n",
       "        0.15521362,  0.20619243, -0.10562573, -0.09422812, -0.21555066,\n",
       "       -0.04667541, -0.0792224 ,  0.03256182, -0.09426205, -0.24983093,\n",
       "        0.13597786, -0.2398801 ,  0.05768704, -0.06787113, -0.4941577 ,\n",
       "       -0.22496416, -0.00669573, -0.03549183,  0.29734784, -0.17858498,\n",
       "       -0.5486123 , -0.14864792, -0.03553995,  0.67317814, -0.076203  ,\n",
       "        0.05146242, -0.18583792, -0.15082437, -0.00156193,  0.05055934,\n",
       "        0.14105804, -0.19593558,  0.21223646,  0.12954028, -0.07022676,\n",
       "        0.07883358, -0.06120036, -0.2503627 , -0.3017727 , -0.13266395,\n",
       "       -0.16572367, -0.18174419,  0.08304436, -0.11019304, -0.19390059,\n",
       "        0.21516724,  0.2340886 , -0.06900662, -0.0862717 ,  0.00340593,\n",
       "       -0.03866918,  0.05421902, -0.11847197, -0.03135929, -0.11774423,\n",
       "       -0.01175743,  0.03097493,  0.02155077, -0.32340154, -0.26865822,\n",
       "        0.10741439,  0.23262182, -0.21423306,  0.15430337,  0.26367036],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sv[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the similarity or distance between two sentence from the training set you can call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965\n",
      "0.035\n"
     ]
    }
   ],
   "source": [
    "print(model.sv.similarity(0,1).round(3))\n",
    "print(model.sv.distance(0,1).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further call for the most similar sentences given an index. For example, we want to know the most similar sentences for sentence index 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Should', 'I', 'buy', 'tiago?'], 100)\n"
     ]
    }
   ],
   "source": [
    "print(s[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:02:46,966 : MainThread : INFO : precomputing L2-norms of sentence vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(5742433, 1.0),\n",
       " (5172303, 1.0),\n",
       " (1657838, 1.0),\n",
       " (5742447, 1.0),\n",
       " (5742445, 1.0),\n",
       " (5742443, 1.0),\n",
       " (5742441, 1.0),\n",
       " (5742439, 1.0),\n",
       " (5742437, 1.0),\n",
       " (5742435, 1.0)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sv.most_similar(100)\n",
    "# Division by zero can happen if you encounter empy sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the preceding function will only supply the indices of the most similar sentences. You can circumvent this problem by passing an indexable function to the most_similar call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['Should', 'I', 'buy', 'Google', 'Glass?'], 5742433, 1.0),\n",
       " (['Why', \"doesn't\", 'Apple', 'buy', 'Samsung?'], 5172303, 1.0),\n",
       " (['Should', 'I', 'buy', 'Moto', 'G4', 'Plus?'], 1657838, 1.0),\n",
       " (['Should', 'I', 'buy', 'Google', 'Glass?'], 5742447, 1.0),\n",
       " (['Should', 'I', 'buy', 'Google', 'Glass?'], 5742445, 1.0),\n",
       " (['Should', 'I', 'buy', 'Google', 'Glass?'], 5742443, 1.0),\n",
       " (['Should', 'I', 'buy', 'Google', 'Glass?'], 5742441, 1.0),\n",
       " (['Should', 'I', 'buy', 'Google', 'Glass?'], 5742439, 1.0),\n",
       " (['Should', 'I', 'buy', 'Google', 'Glass?'], 5742437, 1.0),\n",
       " (['Should', 'I', 'buy', 'Google', 'Glass?'], 5742435, 1.0)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sv.most_similar(100, indexable=s.items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go. This is a lot more understandable than the initial list of indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To search for sentences, which are similar to a given word vector, you can call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['Which',\n",
       "   'is',\n",
       "   'more',\n",
       "   'easy',\n",
       "   'to',\n",
       "   'learn?',\n",
       "   'Ruby',\n",
       "   'on',\n",
       "   'Rails',\n",
       "   'or',\n",
       "   'Python/Django?'],\n",
       "  4717063,\n",
       "  0.9466769099235535),\n",
       " (['Which',\n",
       "   'is',\n",
       "   'more',\n",
       "   'easy',\n",
       "   'to',\n",
       "   'learn?',\n",
       "   'Ruby',\n",
       "   'on',\n",
       "   'Rails',\n",
       "   'or',\n",
       "   'Python/Django?'],\n",
       "  4717065,\n",
       "  0.9466769099235535),\n",
       " (['Which',\n",
       "   'is',\n",
       "   'more',\n",
       "   'easy',\n",
       "   'to',\n",
       "   'learn?',\n",
       "   'Ruby',\n",
       "   'on',\n",
       "   'Rails',\n",
       "   'or',\n",
       "   'Python/Django?'],\n",
       "  4717061,\n",
       "  0.9466769099235535),\n",
       " (['Which',\n",
       "   'is',\n",
       "   'more',\n",
       "   'easy',\n",
       "   'to',\n",
       "   'learn?',\n",
       "   'Ruby',\n",
       "   'on',\n",
       "   'Rails',\n",
       "   'or',\n",
       "   'Python/Django?'],\n",
       "  4717057,\n",
       "  0.9466769099235535),\n",
       " (['Which',\n",
       "   'is',\n",
       "   'more',\n",
       "   'easy',\n",
       "   'to',\n",
       "   'learn?',\n",
       "   'Ruby',\n",
       "   'on',\n",
       "   'Rails',\n",
       "   'or',\n",
       "   'Python/Django?'],\n",
       "  4717067,\n",
       "  0.9466769099235535),\n",
       " (['Which',\n",
       "   'is',\n",
       "   'more',\n",
       "   'easy',\n",
       "   'to',\n",
       "   'learn?',\n",
       "   'Ruby',\n",
       "   'on',\n",
       "   'Rails',\n",
       "   'or',\n",
       "   'Python/Django?'],\n",
       "  4717069,\n",
       "  0.9466769099235535),\n",
       " (['Which',\n",
       "   'is',\n",
       "   'more',\n",
       "   'easy',\n",
       "   'to',\n",
       "   'learn?',\n",
       "   'Ruby',\n",
       "   'on',\n",
       "   'Rails',\n",
       "   'or',\n",
       "   'Python/Django?'],\n",
       "  4717059,\n",
       "  0.9466769099235535),\n",
       " (['Which',\n",
       "   'is',\n",
       "   'more',\n",
       "   'easy',\n",
       "   'to',\n",
       "   'learn?',\n",
       "   'Ruby',\n",
       "   'on',\n",
       "   'Rails',\n",
       "   'or',\n",
       "   'Python/Django?'],\n",
       "  4717071,\n",
       "  0.9466769099235535),\n",
       " (['How', 'can', 'I', 'make', 'some', 'easy', 'money?'],\n",
       "  5443129,\n",
       "  0.9436649680137634),\n",
       " (['How', 'can', 'I', 'make', 'some', 'easy', 'money?'],\n",
       "  5443135,\n",
       "  0.9436649680137634)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sv.similar_by_word(\"easy\", wv=glove, indexable=s.items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, you can query for unknown (or new) sentences by calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:02:52,537 : MainThread : INFO : scanning all indexed sentences and their word counts\n",
      "2022-04-10 21:02:52,537 : MainThread : INFO : finished scanning 1 sentences with an average length of 6 and 6 total words\n",
      "2022-04-10 21:02:52,538 : MainThread : INFO : removing 5 principal components took 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(['How', 'do', 'I', 'learn', 'Python', 'in', 'easy', 'way?'],\n",
       "  418230,\n",
       "  0.9860147833824158),\n",
       " (['How', 'do', 'I', 'learn', 'Python', 'in', 'easy', 'way?'],\n",
       "  418232,\n",
       "  0.9860147833824158),\n",
       " (['How', 'do', 'I', 'learn', 'Python', 'in', 'easy', 'way?'],\n",
       "  418236,\n",
       "  0.9860147833824158),\n",
       " (['How', 'do', 'I', 'learn', 'Python', 'in', 'easy', 'way?'],\n",
       "  6255670,\n",
       "  0.9860147833824158),\n",
       " (['How', 'do', 'I', 'learn', 'Python', 'in', 'easy', 'way?'],\n",
       "  418226,\n",
       "  0.9860147833824158),\n",
       " (['How', 'do', 'I', 'learn', 'Python', 'in', 'easy', 'way?'],\n",
       "  418228,\n",
       "  0.9860147833824158),\n",
       " (['How', 'do', 'I', 'learn', 'Python', 'in', 'easy', 'way?'],\n",
       "  418238,\n",
       "  0.9860147833824158),\n",
       " (['How', 'do', 'I', 'learn', 'Python', 'in', 'easy', 'way?'],\n",
       "  6255666,\n",
       "  0.9860147833824158),\n",
       " (['How', 'do', 'I', 'learn', 'Python', 'in', 'easy', 'way?'],\n",
       "  418234,\n",
       "  0.9860147833824158),\n",
       " (['How', 'do', 'I', 'learn', 'Python', 'in', 'easy', 'way?'],\n",
       "  6255674,\n",
       "  0.9860147833824158)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sv.similar_by_sentence(\"Is this really easy to learn\".split(), model=model, indexable=s.items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to browse through the library and get to know the functions a little better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
